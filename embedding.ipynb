{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n",
    "###### Converting text into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishankarora/langchain-huggingface-krishnaik/langchain-poc/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GoogleGenerativeAIEmbeddings(client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x12ba1cb90>, model='models/embedding-001', task_type=None, google_api_key=SecretStr('**********'), credentials=None, client_options=None, transport=None, request_options=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "embeddings_gemini = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "embeddings_gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01083420030772686,\n",
       " -0.03747275099158287,\n",
       " 0.018611904233694077,\n",
       " -0.010050917975604534,\n",
       " -0.007240986451506615,\n",
       " -0.009738636203110218,\n",
       " 0.06828035414218903,\n",
       " -0.019181478768587112,\n",
       " 0.0188102126121521,\n",
       " 0.008459903299808502,\n",
       " 0.03169867768883705,\n",
       " 0.008393418043851852,\n",
       " -0.0382685624063015,\n",
       " -0.015418659895658493,\n",
       " 0.03981437534093857,\n",
       " -0.03352918475866318,\n",
       " 0.01032938715070486,\n",
       " 0.041751958429813385,\n",
       " -0.016487816348671913,\n",
       " 0.013299061916768551,\n",
       " 0.002750709652900696,\n",
       " -0.033852726221084595,\n",
       " 0.05890961363911629,\n",
       " -0.05611932650208473,\n",
       " -0.0019242401467636228,\n",
       " -0.038302548229694366,\n",
       " 0.03869514912366867,\n",
       " -0.052187807857990265,\n",
       " -0.03992513194680214,\n",
       " 0.04196880757808685,\n",
       " -0.03876261040568352,\n",
       " 0.029854025691747665,\n",
       " 0.006097698118537664,\n",
       " -0.010656667873263359,\n",
       " 0.038707803934812546,\n",
       " -0.04731592535972595,\n",
       " 0.03572917729616165,\n",
       " -0.023595403879880905,\n",
       " 0.018717195838689804,\n",
       " -0.024307625368237495,\n",
       " 0.04577365145087242,\n",
       " -0.040432676672935486,\n",
       " -0.01893983781337738,\n",
       " -0.07161868363618851,\n",
       " -0.004924955777823925,\n",
       " -0.03423357754945755,\n",
       " -0.02378738299012184,\n",
       " 0.016185661777853966,\n",
       " 0.0037114061415195465,\n",
       " -0.0434437021613121,\n",
       " 0.06232146546244621,\n",
       " -0.030165890231728554,\n",
       " 0.005943026393651962,\n",
       " -0.01435672864317894,\n",
       " -0.01534445770084858,\n",
       " -0.0024172670673578978,\n",
       " 0.02281048707664013,\n",
       " 0.02480197697877884,\n",
       " -0.02438170276582241,\n",
       " -0.0015126167563721538,\n",
       " -0.019927583634853363,\n",
       " 0.03438429534435272,\n",
       " -0.06839282065629959,\n",
       " 0.04417511820793152,\n",
       " -0.012638257816433907,\n",
       " -0.06785109639167786,\n",
       " -0.034270189702510834,\n",
       " 0.04626218602061272,\n",
       " 0.000635835574939847,\n",
       " -0.005378791131079197,\n",
       " 0.004550613928586245,\n",
       " -0.03630099073052406,\n",
       " 0.0606890432536602,\n",
       " -0.0412372387945652,\n",
       " -0.017111483961343765,\n",
       " -0.05991838499903679,\n",
       " 0.009889688342809677,\n",
       " 0.03629706799983978,\n",
       " -0.005170275457203388,\n",
       " 0.08314479887485504,\n",
       " 0.006145235616713762,\n",
       " -0.03939070180058479,\n",
       " -0.015726828947663307,\n",
       " 0.0004427715321071446,\n",
       " -0.025319457054138184,\n",
       " 0.027363762259483337,\n",
       " 0.003025081707164645,\n",
       " -0.036079637706279755,\n",
       " -0.01963803544640541,\n",
       " 0.05020242556929588,\n",
       " -0.030241139233112335,\n",
       " 0.01126828882843256,\n",
       " 0.008381328545510769,\n",
       " -0.07934144884347916,\n",
       " -0.01207813061773777,\n",
       " 0.05864514410495758,\n",
       " 0.01957075484097004,\n",
       " 0.0014395026955753565,\n",
       " -0.043364133685827255,\n",
       " -0.030810847878456116,\n",
       " 0.005794030614197254,\n",
       " 0.026493502780795097,\n",
       " 0.022939197719097137,\n",
       " 0.0030382019467651844,\n",
       " 0.029355207458138466,\n",
       " 0.03800193965435028,\n",
       " 0.022950615733861923,\n",
       " 0.09676909446716309,\n",
       " -0.020494382828474045,\n",
       " 0.027429964393377304,\n",
       " -0.03669431805610657,\n",
       " -0.007798832841217518,\n",
       " -0.04332198202610016,\n",
       " -0.003326808800920844,\n",
       " 0.06086127832531929,\n",
       " -0.05566103756427765,\n",
       " 0.02002600207924843,\n",
       " 0.07034347951412201,\n",
       " 0.03906518965959549,\n",
       " 0.014762056060135365,\n",
       " -0.004762106109410524,\n",
       " -0.04029226303100586,\n",
       " 0.05742202699184418,\n",
       " -0.03778892010450363,\n",
       " -0.0075159030966460705,\n",
       " 0.07510067522525787,\n",
       " 0.030284583568572998,\n",
       " 0.011501871980726719,\n",
       " 0.04496731236577034,\n",
       " 0.04157618060708046,\n",
       " -0.02121398039162159,\n",
       " -0.04604668915271759,\n",
       " 0.030844954773783684,\n",
       " 0.02761952020227909,\n",
       " 0.018130315467715263,\n",
       " 0.029607722535729408,\n",
       " 0.05025118216872215,\n",
       " 0.010862549766898155,\n",
       " 0.034951262176036835,\n",
       " 0.0042239283211529255,\n",
       " 0.02259192056953907,\n",
       " 0.030782822519540787,\n",
       " 0.027980443090200424,\n",
       " 0.05733647570014,\n",
       " -0.015061086975038052,\n",
       " -0.012017968110740185,\n",
       " -0.066778264939785,\n",
       " 0.002630686154589057,\n",
       " -0.01120435819029808,\n",
       " -0.03131944686174393,\n",
       " -0.05920103192329407,\n",
       " -0.010613388381898403,\n",
       " -0.08244152367115021,\n",
       " 0.015583833679556847,\n",
       " 0.0340481773018837,\n",
       " -0.00810821820050478,\n",
       " -0.042885977774858475,\n",
       " 0.04162391275167465,\n",
       " 0.014169255271553993,\n",
       " 0.0173799991607666,\n",
       " 0.04152983799576759,\n",
       " 0.017601395025849342,\n",
       " -0.0045868041925132275,\n",
       " 0.0192395206540823,\n",
       " -0.012707107700407505,\n",
       " 0.027819735929369926,\n",
       " -0.011632229201495647,\n",
       " 0.010184336453676224,\n",
       " -0.025337330996990204,\n",
       " -0.004662428051233292,\n",
       " 0.00727105513215065,\n",
       " 0.026234997436404228,\n",
       " -0.06047511473298073,\n",
       " -0.06645305454730988,\n",
       " -0.02630118653178215,\n",
       " -0.03206007555127144,\n",
       " -0.03107873536646366,\n",
       " 0.016628364101052284,\n",
       " 0.024530356749892235,\n",
       " -0.0196902584284544,\n",
       " -0.02355242893099785,\n",
       " -0.011632000096142292,\n",
       " -0.01631663180887699,\n",
       " 0.04539141803979874,\n",
       " 0.04930172488093376,\n",
       " 0.01796746253967285,\n",
       " 0.05162934958934784,\n",
       " -0.031138326972723007,\n",
       " 0.0009422414586879313,\n",
       " -0.012036214582622051,\n",
       " -0.016642624512314796,\n",
       " -0.030140021815896034,\n",
       " -0.02534107305109501,\n",
       " -0.01095884945243597,\n",
       " -0.00998657662421465,\n",
       " 0.017019003629684448,\n",
       " -0.010410208255052567,\n",
       " 0.04147058352828026,\n",
       " 0.03243161737918854,\n",
       " -0.0018588741077110171,\n",
       " 0.027668634429574013,\n",
       " 0.06938105076551437,\n",
       " 0.022962059825658798,\n",
       " -0.024327712133526802,\n",
       " 0.041164714843034744,\n",
       " -0.024569397792220116,\n",
       " 0.05744897946715355,\n",
       " -0.02905549295246601,\n",
       " -0.06394891440868378,\n",
       " 0.005147967953234911,\n",
       " -0.049976661801338196,\n",
       " -0.019635438919067383,\n",
       " -0.047561272978782654,\n",
       " -0.0041084312833845615,\n",
       " 0.050927165895700455,\n",
       " 0.02786870487034321,\n",
       " 0.004714924842119217,\n",
       " 0.0422525517642498,\n",
       " -0.017871500924229622,\n",
       " -0.0271912794560194,\n",
       " -0.009903122670948505,\n",
       " -0.021935921162366867,\n",
       " 0.006741534452885389,\n",
       " 0.018418828025460243,\n",
       " -0.03988196700811386,\n",
       " 0.07599703222513199,\n",
       " -0.05321400985121727,\n",
       " 0.026049956679344177,\n",
       " 0.04100937768816948,\n",
       " -0.04356974735856056,\n",
       " 0.01907440833747387,\n",
       " 0.0450972355902195,\n",
       " 0.03184999153017998,\n",
       " -0.022367006167769432,\n",
       " 0.04959985613822937,\n",
       " -0.010840002447366714,\n",
       " 0.0137315783649683,\n",
       " 0.01181824505329132,\n",
       " 0.0028959724586457014,\n",
       " -0.03795652836561203,\n",
       " -0.058363813906908035,\n",
       " 0.007406558375805616,\n",
       " 0.020894521847367287,\n",
       " 0.012111110612750053,\n",
       " -0.05659932643175125,\n",
       " -0.057350486516952515,\n",
       " -0.03359550982713699,\n",
       " 0.042647164314985275,\n",
       " -0.029254458844661713,\n",
       " 0.004331778734922409,\n",
       " -0.04965297505259514,\n",
       " -0.029885821044445038,\n",
       " 0.04577429220080376,\n",
       " -0.012055723927915096,\n",
       " -0.04515762999653816,\n",
       " 0.04274611547589302,\n",
       " -0.01619636081159115,\n",
       " -0.053967803716659546,\n",
       " 0.014034176245331764,\n",
       " 0.038375530391931534,\n",
       " 0.021964283660054207,\n",
       " 0.02948843501508236,\n",
       " -0.006531710270792246,\n",
       " -0.05419910326600075,\n",
       " -0.0032848729752004147,\n",
       " -0.010482226498425007,\n",
       " 0.03993821516633034,\n",
       " -0.12542349100112915,\n",
       " -0.013687261380255222,\n",
       " 0.01761978678405285,\n",
       " -0.03536800295114517,\n",
       " -0.06223871186375618,\n",
       " 0.026573529466986656,\n",
       " -0.013624880462884903,\n",
       " -0.08043166995048523,\n",
       " -0.012935103848576546,\n",
       " 0.0013452837010845542,\n",
       " -0.024262424558401108,\n",
       " -0.01362115889787674,\n",
       " -0.011711431667208672,\n",
       " 0.060652006417512894,\n",
       " 0.04720098897814751,\n",
       " 0.03566741198301315,\n",
       " -0.03759491443634033,\n",
       " -0.049462080001831055,\n",
       " 0.023005442693829536,\n",
       " -0.00098208908457309,\n",
       " -0.037270139902830124,\n",
       " 0.036936305463314056,\n",
       " -0.09051405638456345,\n",
       " -0.03274926543235779,\n",
       " 0.03230488672852516,\n",
       " -0.01564127393066883,\n",
       " -0.04035639762878418,\n",
       " 0.0007102913223206997,\n",
       " 0.018680797889828682,\n",
       " 0.015242641791701317,\n",
       " -0.020068122074007988,\n",
       " 0.025561871007084846,\n",
       " -0.03535589575767517,\n",
       " 0.009984340518712997,\n",
       " -0.020097531378269196,\n",
       " -0.039539314806461334,\n",
       " -0.0414993055164814,\n",
       " -0.007353253196924925,\n",
       " 0.011133329011499882,\n",
       " 0.005158565938472748,\n",
       " -0.058624401688575745,\n",
       " -0.02810613624751568,\n",
       " -0.0005719423061236739,\n",
       " -0.002606905298307538,\n",
       " -0.015587976202368736,\n",
       " -0.056866783648729324,\n",
       " -0.013674569316208363,\n",
       " 0.0780666247010231,\n",
       " -0.006547024007886648,\n",
       " -0.01392004918307066,\n",
       " 0.03988518938422203,\n",
       " -0.00037188504938967526,\n",
       " 0.02665693499147892,\n",
       " -0.010096022859215736,\n",
       " 0.06393832713365555,\n",
       " -0.013274977914988995,\n",
       " -0.00492623308673501,\n",
       " 0.007092980667948723,\n",
       " 0.005135581828653812,\n",
       " -0.07128559798002243,\n",
       " 0.05351914465427399,\n",
       " -0.022942792624235153,\n",
       " 0.029566217213869095,\n",
       " 0.0489729680120945,\n",
       " -0.03859424591064453,\n",
       " -0.02826223149895668,\n",
       " 0.021670663729310036,\n",
       " 0.028829947113990784,\n",
       " 0.04498504474759102,\n",
       " -0.040695447474718094,\n",
       " -0.02277308702468872,\n",
       " -0.034326959401369095,\n",
       " -0.03208886831998825,\n",
       " 0.008077347651124,\n",
       " 0.010691259987652302,\n",
       " -0.05183996632695198,\n",
       " -0.03287123143672943,\n",
       " 0.004913256503641605,\n",
       " 0.0014782280195504427,\n",
       " -0.023572683334350586,\n",
       " -0.011474277824163437,\n",
       " 0.08355904370546341,\n",
       " -0.018208080902695656,\n",
       " -0.008636999875307083,\n",
       " 0.04806256294250488,\n",
       " 0.001852804096415639,\n",
       " 0.033348456025123596,\n",
       " 0.012817123904824257,\n",
       " -0.020552974194288254,\n",
       " 0.05873493105173111,\n",
       " -0.06323323398828506,\n",
       " 0.03843109309673309,\n",
       " 0.0012756413780152798,\n",
       " -0.017831822857260704,\n",
       " 0.0011830893345177174,\n",
       " 0.00991551298648119,\n",
       " -0.006753849796950817,\n",
       " 0.06218760833144188,\n",
       " 0.017981747165322304,\n",
       " -0.004154297057539225,\n",
       " -0.02065568044781685,\n",
       " 0.011214991100132465,\n",
       " 0.009709985926747322,\n",
       " 0.02291932702064514,\n",
       " -0.027101268991827965,\n",
       " 0.008199031464755535,\n",
       " -0.049584850668907166,\n",
       " 0.029182350262999535,\n",
       " -0.033676877617836,\n",
       " -0.039128243923187256,\n",
       " -0.026184266433119774,\n",
       " 0.050877224653959274,\n",
       " 0.00551963597536087,\n",
       " -0.01565943844616413,\n",
       " -0.037548668682575226,\n",
       " 0.043882980942726135,\n",
       " 0.06059412285685539,\n",
       " 0.014690871350467205,\n",
       " -0.02563496120274067,\n",
       " 0.052710067480802536,\n",
       " 0.012807424180209637,\n",
       " -0.00019577912462409586,\n",
       " 0.00043563268263824284,\n",
       " 0.026272503659129143,\n",
       " -0.020320694893598557,\n",
       " 0.059630729258060455,\n",
       " 0.00887216255068779,\n",
       " 0.01589142344892025,\n",
       " -0.017811208963394165,\n",
       " -0.01162276417016983,\n",
       " -0.025222791358828545,\n",
       " -0.004300191067159176,\n",
       " -0.03412224352359772,\n",
       " -0.024388693273067474,\n",
       " 0.005475438199937344,\n",
       " -0.06067381799221039,\n",
       " -0.012586419470608234,\n",
       " -0.013175493106245995,\n",
       " -0.012129157781600952,\n",
       " 0.016054032370448112,\n",
       " -0.01832403428852558,\n",
       " -0.0247103963047266,\n",
       " -0.04373291879892349,\n",
       " 0.05646520480513573,\n",
       " 0.04943164438009262,\n",
       " 0.038253504782915115,\n",
       " -0.056356385350227356,\n",
       " -0.04045085981488228,\n",
       " -0.02895701490342617,\n",
       " 0.047166794538497925,\n",
       " -0.018488047644495964,\n",
       " 0.01917637512087822,\n",
       " 0.0714440643787384,\n",
       " -0.005536749958992004,\n",
       " -0.0014459524536505342,\n",
       " 0.0017720719333738089,\n",
       " -0.06427516043186188,\n",
       " -0.02401120215654373,\n",
       " -0.03797402232885361,\n",
       " -0.01528658252209425,\n",
       " -0.032365117222070694,\n",
       " 0.014079462736845016,\n",
       " 0.02601468749344349,\n",
       " -0.001975059974938631,\n",
       " 0.057200703769922256,\n",
       " -0.01511585433036089,\n",
       " 0.03175063803792,\n",
       " 0.004916623700410128,\n",
       " -0.06501259654760361,\n",
       " 0.03204168751835823,\n",
       " -0.013654971495270729,\n",
       " -0.04518219083547592,\n",
       " -0.05487849935889244,\n",
       " 0.023220710456371307,\n",
       " -0.001957124564796686,\n",
       " 0.01762959361076355,\n",
       " 0.011429758742451668,\n",
       " -0.08406287431716919,\n",
       " 0.007566186599433422,\n",
       " 0.013633894734084606,\n",
       " -0.019967779517173767,\n",
       " 0.023111028596758842,\n",
       " -0.07587602734565735,\n",
       " 0.013781155459582806,\n",
       " -0.017985699698328972,\n",
       " -0.010338634252548218,\n",
       " -0.06869234889745712,\n",
       " -0.03996437415480614,\n",
       " -0.038270529359579086,\n",
       " 0.0018128586234524846,\n",
       " 0.09094427525997162,\n",
       " 0.008797459304332733,\n",
       " -0.030532976612448692,\n",
       " -0.0021719918586313725,\n",
       " -0.02820759266614914,\n",
       " -0.03719284385442734,\n",
       " -0.1029478907585144,\n",
       " 0.017126036807894707,\n",
       " -0.046404048800468445,\n",
       " 0.006116286385804415,\n",
       " -0.0010681294370442629,\n",
       " 0.032032959163188934,\n",
       " 0.07278177887201309,\n",
       " 0.05078708752989769,\n",
       " -0.007955548353493214,\n",
       " 0.0117857176810503,\n",
       " -0.0197890717536211,\n",
       " 0.026360847055912018,\n",
       " -0.0009040668373927474,\n",
       " -0.10593824833631516,\n",
       " -0.004356279503554106,\n",
       " 0.017160600051283836,\n",
       " -0.04437331482768059,\n",
       " 0.019082086160779,\n",
       " 0.06878312677145004,\n",
       " 0.011509657837450504,\n",
       " -0.01479710079729557,\n",
       " -0.06819140911102295,\n",
       " -0.05774321034550667,\n",
       " 0.05820225179195404,\n",
       " 0.026178624480962753,\n",
       " 0.010921737179160118,\n",
       " 0.04733436927199364,\n",
       " -0.02786816842854023,\n",
       " 0.005942682269960642,\n",
       " 0.004939037840813398,\n",
       " -0.004314993042498827,\n",
       " 0.0024291491135954857,\n",
       " 0.024389414116740227,\n",
       " -0.03938986733555794,\n",
       " 0.029458068311214447,\n",
       " 0.06610778719186783,\n",
       " 0.07948263734579086,\n",
       " 0.00434807687997818,\n",
       " 0.0013882945058867335,\n",
       " -0.030894022434949875,\n",
       " -0.04406431317329407,\n",
       " 0.03775118291378021,\n",
       " -0.1061004027724266,\n",
       " 0.03477802500128746,\n",
       " 0.025870060548186302,\n",
       " 0.017079202458262444,\n",
       " -0.042217206209897995,\n",
       " 0.004105718340724707,\n",
       " -0.019623825326561928,\n",
       " 0.04513280466198921,\n",
       " -0.025736762210726738,\n",
       " 0.0768306776881218,\n",
       " -0.07831721007823944,\n",
       " 0.020973974838852882,\n",
       " 0.0024674735032022,\n",
       " 0.024974515661597252,\n",
       " 0.02533363364636898,\n",
       " 0.05108949914574623,\n",
       " 0.0004406437510624528,\n",
       " -0.07978285104036331,\n",
       " 0.021427882835268974,\n",
       " 0.028477229177951813,\n",
       " -0.04810649901628494,\n",
       " -0.009221749380230904,\n",
       " 0.03776577115058899,\n",
       " 0.013683980330824852,\n",
       " -0.023054976016283035,\n",
       " -0.029222844168543816,\n",
       " 0.0642494186758995,\n",
       " -0.14524084329605103,\n",
       " -0.021822119131684303,\n",
       " 0.0317969024181366,\n",
       " -0.030759727582335472,\n",
       " -0.02794395200908184,\n",
       " 0.01118716225028038,\n",
       " 0.023114051669836044,\n",
       " -0.013681317679584026,\n",
       " 0.03241715580224991,\n",
       " -0.024172183126211166,\n",
       " 0.020746642723679543,\n",
       " -0.028421727940440178,\n",
       " 0.03584868460893631,\n",
       " -0.0035377044696360826,\n",
       " 0.034001387655735016,\n",
       " -0.08298146724700928,\n",
       " 0.001717237988486886,\n",
       " 0.008057364262640476,\n",
       " -0.0269112940877676,\n",
       " -0.018963554874062538,\n",
       " -0.000579220533836633,\n",
       " -0.028478167951107025,\n",
       " 0.04787278175354004,\n",
       " -0.0015612720744684339,\n",
       " -0.04826534911990166,\n",
       " 0.010587877593934536,\n",
       " 0.038125649094581604,\n",
       " 0.017367083579301834,\n",
       " -0.014783155173063278,\n",
       " -0.006993792951107025,\n",
       " 0.04574510082602501,\n",
       " -0.004119934048503637,\n",
       " 0.025084372609853745,\n",
       " -0.005921614822000265,\n",
       " -0.03413292393088341,\n",
       " -0.012136382982134819,\n",
       " 0.045516736805438995,\n",
       " -0.017496207728981972,\n",
       " -0.036727484315633774,\n",
       " 0.028389321640133858,\n",
       " -0.004270268604159355,\n",
       " 0.024971649050712585,\n",
       " 0.042135123163461685,\n",
       " -0.06768259406089783,\n",
       " -0.003832581453025341,\n",
       " -0.010043787769973278,\n",
       " -0.011236432939767838,\n",
       " -0.007460525259375572,\n",
       " 0.0035642117727547884,\n",
       " -0.031506992876529694,\n",
       " -0.033114783465862274,\n",
       " 0.033563461154699326,\n",
       " 0.027609918266534805,\n",
       " -0.002056984230875969,\n",
       " 0.03456123173236847,\n",
       " -0.0014765753876417875,\n",
       " 0.014142729341983795,\n",
       " -0.008758844807744026,\n",
       " -0.06857306510210037,\n",
       " 0.04450763761997223,\n",
       " -0.05394483357667923,\n",
       " -0.07252813130617142,\n",
       " -0.005829587113112211,\n",
       " 0.006299460772424936,\n",
       " -0.02044682577252388,\n",
       " 0.0004251400241628289,\n",
       " -0.0019187962170690298,\n",
       " 0.04583476111292839,\n",
       " 0.01576235517859459,\n",
       " -0.04496137797832489,\n",
       " 0.10498422384262085,\n",
       " -0.037057630717754364,\n",
       " 0.01990242302417755,\n",
       " 0.024522792547941208,\n",
       " -0.02354581467807293,\n",
       " -0.010469506494700909,\n",
       " -0.008527045138180256,\n",
       " 0.027742523699998856,\n",
       " -0.013533372431993484,\n",
       " -0.04306161031126976,\n",
       " 0.03165047988295555,\n",
       " -0.007417827844619751,\n",
       " -0.05531636252999306,\n",
       " -0.01550943125039339,\n",
       " 0.03691759333014488,\n",
       " -0.004950590431690216,\n",
       " -0.006402005907148123,\n",
       " -0.03189012408256531,\n",
       " -0.019651254639029503,\n",
       " 0.021154535934329033,\n",
       " -0.01927807927131653,\n",
       " -0.0053482819348573685,\n",
       " 0.04631797969341278,\n",
       " 0.035177700221538544,\n",
       " -0.020623045042157173,\n",
       " -0.00829293578863144,\n",
       " 0.03945904225111008,\n",
       " 0.02016509883105755,\n",
       " 0.026022858917713165,\n",
       " 0.05057340860366821,\n",
       " 0.03221634030342102,\n",
       " -0.03138255700469017,\n",
       " -0.004798179492354393,\n",
       " -0.0027389233000576496,\n",
       " 0.008128016255795956,\n",
       " -0.01019873283803463,\n",
       " 0.058309078216552734,\n",
       " -0.028550704941153526,\n",
       " -0.11974191665649414,\n",
       " -0.0049655502662062645,\n",
       " 0.023606866598129272,\n",
       " -0.04107694327831268,\n",
       " -0.027170294895768166,\n",
       " 0.025356918573379517,\n",
       " 0.025805644690990448,\n",
       " -0.06321828067302704,\n",
       " -0.027694791555404663,\n",
       " 0.026020128279924393,\n",
       " 0.027904139831662178,\n",
       " -0.00195127387996763,\n",
       " 0.021377764642238617,\n",
       " -0.01801903173327446,\n",
       " -0.035021983087062836,\n",
       " 0.014096627943217754,\n",
       " -0.06305067986249924,\n",
       " -0.055994659662246704,\n",
       " -0.0034614091273397207,\n",
       " -0.06471841037273407,\n",
       " -0.05707305669784546,\n",
       " 0.02139417827129364,\n",
       " 0.0161018967628479,\n",
       " -0.016220565885305405,\n",
       " -0.002914102515205741,\n",
       " -0.06891779601573944,\n",
       " -0.031822893768548965,\n",
       " -0.05939263850450516,\n",
       " -0.04573414474725723,\n",
       " -0.02465008571743965,\n",
       " -0.01664116233587265,\n",
       " 0.07752636075019836,\n",
       " 0.0038635849487036467,\n",
       " -0.016518794000148773,\n",
       " 0.03175948187708855,\n",
       " 0.006713607348501682,\n",
       " -0.05032958462834358,\n",
       " 0.04949379339814186,\n",
       " 0.02044697292149067,\n",
       " 0.05793922394514084,\n",
       " 0.005181167274713516,\n",
       " -0.03908383101224899,\n",
       " -0.01812833733856678,\n",
       " 0.023836808279156685,\n",
       " 0.04749417304992676,\n",
       " 0.030309678986668587,\n",
       " 0.019569801166653633,\n",
       " 0.008144679479300976,\n",
       " -0.019681744277477264,\n",
       " -0.02088780887424946,\n",
       " -0.024126701056957245,\n",
       " 0.008104044012725353,\n",
       " -0.05025172978639603,\n",
       " -0.014097513630986214,\n",
       " 0.056760504841804504,\n",
       " 0.04015956073999405,\n",
       " -0.05792245641350746,\n",
       " 0.00651957094669342,\n",
       " 0.05796550586819649,\n",
       " 0.0506877563893795,\n",
       " -0.014574844390153885,\n",
       " -0.06417769193649292,\n",
       " -0.007235598750412464,\n",
       " -0.02015383541584015,\n",
       " 0.017566125839948654,\n",
       " -0.013234364800155163,\n",
       " 0.010445227846503258,\n",
       " -0.010101604275405407,\n",
       " 0.010343164205551147,\n",
       " -0.025094378739595413,\n",
       " 0.028423335403203964,\n",
       " -0.0469135046005249,\n",
       " -0.04828530550003052,\n",
       " 0.014265768229961395,\n",
       " -0.0139211006462574,\n",
       " -0.019464537501335144,\n",
       " 0.00805162824690342,\n",
       " -0.013243811205029488,\n",
       " -0.020180292427539825,\n",
       " 0.061749167740345,\n",
       " 0.003799205180257559,\n",
       " 0.025164928287267685,\n",
       " -0.009097968228161335,\n",
       " -0.03197147324681282,\n",
       " -0.05158429592847824,\n",
       " 0.03547968342900276,\n",
       " -0.01628972962498665,\n",
       " 0.02108030952513218,\n",
       " -0.04565975442528725,\n",
       " -0.012836646288633347,\n",
       " 0.039727769792079926,\n",
       " -0.02430504560470581,\n",
       " 0.04842912405729294,\n",
       " 0.07010263949632645,\n",
       " -0.06914522498846054,\n",
       " 0.07010147720575333,\n",
       " -0.007275340612977743,\n",
       " 0.01817350462079048,\n",
       " -0.05360656604170799,\n",
       " -0.04875630512833595,\n",
       " -0.006357838865369558,\n",
       " -0.020258704200387,\n",
       " 0.024540739133954048,\n",
       " 0.0346168614923954,\n",
       " -0.03344196081161499,\n",
       " -0.06600743532180786,\n",
       " 0.034400541335344315,\n",
       " -0.020633289590477943,\n",
       " 0.006651760544627905,\n",
       " -0.007084592245519161,\n",
       " -0.04137049615383148,\n",
       " 0.009713474661111832,\n",
       " 0.005226598586887121,\n",
       " 0.048940181732177734,\n",
       " 0.04633495584130287,\n",
       " -0.019004816189408302,\n",
       " 0.015002576634287834,\n",
       " 0.03130333870649338,\n",
       " 0.010074151679873466,\n",
       " 0.006358816288411617,\n",
       " -0.03271123766899109,\n",
       " 0.054103780537843704,\n",
       " -0.002680146833881736,\n",
       " 0.000855369318742305,\n",
       " 0.033946238458156586,\n",
       " 0.022877823561429977,\n",
       " -0.018555333837866783,\n",
       " 0.03183987736701965]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a tutorial on OPENAI Embedding\"\n",
    "query_result = embeddings_gemini.embed_query(text)\n",
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x10e95c1d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Vector Embedding and Vector StoreDb\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "docs = ArxivLoader(query=\"1706.03762\", load_max_docs=2).load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "final_documents = text_splitter.split_documents(docs)\n",
    "db = Chroma.from_documents(final_documents, embeddings_gemini)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Published': '2023-08-02', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.', 'Title': 'Attention Is All You Need'}, page_content='Full attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis'),\n",
       " Document(metadata={'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Published': '2023-08-02', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.', 'Title': 'Attention Is All You Need'}, page_content=',\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\\nsentence. We give two such examples above, from two different heads from the encoder self-attention\\nat layer 5 of 6. The heads clearly learned to perform different tasks.\\n15'),\n",
       " Document(metadata={'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Published': '2023-08-02', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.', 'Title': 'Attention Is All You Need'}, page_content='encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\\n13\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat'),\n",
       " Document(metadata={'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Published': '2023-08-02', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.', 'Title': 'Attention Is All You Need'}, page_content='but\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Retrieve the results from query vectorstore db\n",
    "\n",
    "query = \"the complaints and disappointment may hardly improve the recent state\"\n",
    "retrieved_results = db.similarity_search(query)\n",
    "retrieved_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
